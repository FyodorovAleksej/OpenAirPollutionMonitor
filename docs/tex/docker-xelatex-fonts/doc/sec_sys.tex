\section{СИСТЕМНОЕ ПРОЕКТИРОВАНИЕ}
\label{sec:sys}

Изучив теоретические аспекты разрабатываемой системы и выработав
список требований необходимых для разработки системы, разбиваем систему
на функциональные блоки(модули). Это необходимо для обеспечения гибкой
архитектуры. Такой подход позволяет изменять или заменять модули без
изменения всей системы в целом.

В разрабатываемом веб-приложении можно выделить следующие
блоки:

\begin{itemize}
    \item блок загрузки данных;
    \item блок преобразования данных;
    \item блок передачи сообщений;
    \item блок приёма сообщений;
    \item блок анализа данных;
    \item блок сохранения данных;
    \item блок визуализации данных.
\end{itemize}
Взаимосвязь между основными компонентами проекта отражена на структурной схеме
ГУИР.400201.079 С1.

\subsection{Блок загрузки данных}

Блок загрузки данных предназначен для получения информацию из удалённого источника.
В качестве такого источника выступает сервис OpenWeatherMap~\cite{open_weather_map_index}.
Данный сервис поддерживает множество application programming interfaces (API), для выборки данных.
Конкретно для текущих целей используются API для следующих данных:
\begin{itemize}
    \item индекс моноооксида углерода ($ \text{CO} $);
    \item индекс озона ($ \text{O}_{\text{3}} $);
    \item индекс диоксида серы ($ \text{SO}_{\text{2}} $);
    \item индекс диоксида азота ($ \text{NO}_{\text{2}} $).
\end{itemize}

Рассматриваемый блок использует каждый вышеперечисленный API для получения данных.
Посредством использования HyperText Tranfer Protocol (HTTP) запроса, блок получает необходимые данные.
Данные предоставляются в формате JavaScript Object Notation (JSON).
Данный формат позволяет легко получить необходимые поля предоставляемых данных.

Из-за использования модульной структуры данный блок можно заменить блоком, который будет предоставлять локальные данные.
Таким образом при отсутствии должного количества данных, есть возможность воспользоваться локальным датасетом.
Полученные данным блоком данные отправляются в блок преобразования данных.

\subsection{Блок преобразования данных}

Блок преобразования данных осуществляет преобразования исходных данных, полученных в формате JSON в необходимые для дальнейшего анализа данные.
Текущая структура JSON данных, предоставляемая сервисом OpenWeatherMap имеет множество полей, которые несут дополнительную информацию.
Например, в таком формате хранятся данные о исследуемом индексе на различных высотах с разным атмосферным давлением.
Как указано в документации к данному сервису, для анализа рекомендуется брать значения между 215 и 0.00464 гектопаскалей (hPa).
Поэтому целью рассматриваемого блока и является выбор необходимых значений из предоставляемого формата.
Для каждого индекса используется свой трансформатор, так как структура JSON для некоторых индексов отличается.
Все эти данные преобразуются в цифровые значения и перенаправляются в блок передачи сообщений.

\subsection{Блок передачи сообщений}

Блок передачи данных предназначен для отправки подготовленных данных в очередь сообщений.
Данная операция необходима для того, чтобы абсолютно любые компоненты системы смогли получить обработанные данные и обработать их своим способом.
В качестве очереди сообщений выступает, описанная в предыдущем разделе, платформа kafka.
Данная платформа позволит остальным компонентам системы своевременно получить подготовленные данные и начать их обработку.

Одними из важнейших особенностей платформы kafka являются наличие топиков, и представление сообщения как пары ключ-значение.
Также на каждый предоставляемый индекс будет использоваться отдельны топик.
И из-за использования системы подписки, остальные компоненты системы могут отлавливать только интересующие их индексы.
Такой метод позволяет использовать один источник данных для всех компонентов системы.
Тем самым обеспечив разрабатываемой системе гибкость и вертикальную расширяемость.

Ещё одним не маловажным фактором выбором kafka является её отказоустойчивость.
Все эти сообщения будут храниться на кластере.
Тем самым, все отправленные данные не потеряются при внезапном отключении машины в кластере.


\subsection{Блок приёма сообщений}

Блок приёма сообщений отвечает за своевременное принятие сообщений из платформы kafka.
Как только данные были получены, они сразу же начинают обработку.
Такое поведение называется потоковой обработкой (англ. stream processing).

На самом деле обрабатываеются данные, полученные за установленный период времени.
Данный промежуток времени называется окном (англ. window).
Данные, полученные за такое окно называется микропакетом (англ. micro batch).
При обработке в Apache Spark каждый такой микропакет будет представлять из себя отдельный RDD, над которым и будут в дальнейшем производиться все операции.

Данному блоку необходимо обеспечить получение данных из конкретных топиков для дальнейшей обработки.
Таким образом, есть возможность установить, какие именно данные начнут обрабатываться.
Как было отмечено выше, все полученные индексы используются в дальнейшей обработке, так что этот блок должен принимать данные по каждому индексу.

Источником данных служит уже рассмотренная выше платформа kafka.
С помощью установки смещения, есть возможность установить, с какого момента данные будут поступать в систему.
Тем самым можно использовать только самые актуальные данные, либо использовать предыдущие данные в качестве датасета.

Так как все приёмники объединяютя в группы (англ. consumer group), то есть возможность создания блока, который будет параллельно обрабатывать те же самые данные, с точно таким же смещением.
Как раз с помощью данной особенности, данные и обрабатываются параллельно при использовании Apache Spark.
Так как код отправляется на активные машины в кластере, то и каждая машина будет параллельно получать данные из kafka платформы, а так как все они входят в одну и ту же принимающую группу, то и данные они будут получать идентичные.
Такой подход обеспечивает вертикальную масштабируемость системы.
Полученные сообщения отправляются в блок анализа данных и в блок сохранения данных.

\subsection{Блок анализа данных}

Блок анализа данных предназначен для обработки полученных данных.
Результаты обработки поступают на блок визуализации данных.

\subsection{Блок сохранения данных}

Блок сохранения данных предназначен для сохранения полученных данных на диске.
Так как в качестве обработчика используетсся целый кластер, то и сохранение возможно осуществить как в локальной файловой системе, так и в распределённой файловой системе платформы Hadoop (англ. Hadoop Distributed File System (HDFS)).
Сохранение данных нужно для восстановления предыдущих данных после перезапуска системы.
В течении жизненого цикла приложения в данном блоке нет необходимости, так как все данные успешно хранятся в платформе kafka.
Однако при полной перезагрузке системы, придётся заново получать данные из внешнего веб-сервиса OpenWeatherMap. 
Данный блок предназначен как раз для того, чтобы этого избежать такой проблемы.

При использовании экосистемы Hadoop появляется возможность сохранения данных в HDFS.
В отличие от локальной файловой системы, данная система является распределённой, что обеспечивает её отказоустойчивость.

Основные свойства HDFS:
\begin{itemize}
    \item Предназначена для хранения большого количества больших файлов (порядка десятков гигабайт).
    \item Оптимизирована для поддержки потокового доступа к данным (англ. high-streaming read).
    \item Ориентирована использование кластера большого размера.
    \item Отказоустойчивость.
\end{itemize}

Все накопленные данные сохраняются в локальном хранилище, что позволяет сразу загрузить уже полученные данные.
А из платформы kafka получать только новые данные, которые ещё не были загружены.
Таким образом достигается оптимизация приложения и возможность восстановления процесса обработки при перезапуске системы.


\subsection{Блок визуализации данных}

Блок визуализации данных предназначен для интерактивного представления обработанных результатов.
Для подобного представления используется такая система, как Apache Zeppelin.
Как уже отмечалось, Apache Zeppelin использует интерактивные документы, которые используют концепцию интерпретатора, что позволяет моментально визуализировать результаты вычислений.
Данная система крайне схожа с проектом Jupyter Notebook по концепции.
Она также, как и Jupyter использует интерактивные документы (англ. notebooks).

Данный блок как раз представляет из себя интерактивный документ в системе Apache Zeppelin.
Такой подход позволяет использовать совершенно разные способы предоставления данных, а так же в режиме реального времени визуализировать текущие результаты.
