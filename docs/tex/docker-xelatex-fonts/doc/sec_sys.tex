\section{СИСТЕМНОЕ ПРОЕКТИРОВАНИЕ}
\label{sec:sys}

Изучив теоретические аспекты разрабатываемой системы и выработав
список требований необходимых для разработки системы, разбиваем систему
на функциональные блоки(модули). Это необходимо для обеспечения гибкой
архитектуры. Такой подход позволяет изменять или заменять модули без
изменения всей системы в целом.

В разрабатываемом веб-приложении можно выделить следующие
блоки:

\begin{itemize}
    \item блок загрузки данных;
    \item блок преобразования данных;
    \item блок передачи сообщений;
    \item блок приёма сообщений;
    \item блок анализа данных;
    \item блок сохранения данных;
    \item блок визуализации данных.
\end{itemize}
Взаимосвязь между основными компонентами проекта отражена на структурной схеме
ГУИР.400201.079 С1.

\subsection{Блок загрузки данных}

Блок загрузки данных предназначен для получения информацию из удалённого источника.
В качестве такого источника выступает сервис OpenWeatherMap~\cite{open_weather_map_index}.
Данный сервис поддерживает множество application programming interfaces (API), для выборки данных.
Конкретно для текущих целей используются API для следующих данных:
\begin{itemize}
    \item индекс монооксида углерода ($ \text{CO} $);
    \item индекс озона ($ \text{O}_{\text{3}} $);
    \item индекс диоксида серы ($ \text{SO}_{\text{2}} $);
    \item индекс диоксида азота ($ \text{NO}_{\text{2}} $).
\end{itemize}

Рассматриваемый блок использует каждый вышеперечисленный API для получения данных.
Посредством использования HyperText Tranfer Protocol (HTTP) запроса, блок получает необходимые данные.
Данные предоставляются в формате JavaScript Object Notation (JSON).
Данный формат позволяет легко получить необходимые поля предоставляемых данных.

У используемого сервиса есть ограничение в виде максимального количества запросов по API в единицу времени.
На текущий момент это ограничение составляет 10 запросов в минуту.
Для обхода данного ограничения, используется локальное хранилище уже полученных данных.
С помощью такого метода, данный блок будет обращаться к внешнему серверу только для получения данных, которых нету в локальном хранилище.
Если же требуемый запрос уже был совершён и был сохранён, то вместо обращения к серверу, блок отправит данные из локального хранилища.

Также, из-за использования модульной структуры данный блок можно заменить блоком, который будет предоставлять локальные данные.
Таким образом при отсутствии должного количества данных, есть возможность воспользоваться локальным датасетом.
Полученные данным блоком данные отправляются в блок преобразования данных.

\subsection{Блок преобразования данных}

Блок преобразования данных осуществляет преобразования исходных данных, полученных в формате JSON в необходимые для дальнейшего анализа данные.
Текущая структура JSON данных, предоставляемая сервисом OpenWeatherMap имеет множество полей, которые несут дополнительную информацию.
Например, в таком формате хранятся данные о исследуемом индексе на различных высотах с разным атмосферным давлением.
Как указано в документации к данному сервису, для анализа рекомендуется брать значения между 215 и 0.00464 гектопаскалей (hPa).
Поэтому целью рассматриваемого блока и является выбор необходимых значений из предоставляемого формата.
Для каждого индекса используется свой трансформатор, так как структура JSON для некоторых индексов отличается.
Все эти данные преобразуются в цифровые значения и перенаправляются в блок передачи сообщений.

\subsection{Блок передачи сообщений}

Блок передачи данных предназначен для отправки подготовленных данных в очередь сообщений.
Данная операция необходима для того, чтобы абсолютно любые компоненты системы смогли получить обработанные данные и обработать их своим способом.
В качестве очереди сообщений выступает, описанная в предыдущем разделе, платформа kafka.
Данная платформа позволит остальным компонентам системы своевременно получить подготовленные данные и начать их обработку.

Одними из важнейших особенностей платформы Kafka являются наличие топиков, и представление сообщения как пары ключ-значение.
Также на каждый предоставляемый индекс будет использоваться отдельны топик.
И из-за использования системы подписки, остальные компоненты системы могут отлавливать только интересующие их индексы.
Такой метод позволяет использовать один источник данных для всех компонентов системы.
Тем самым обеспечив разрабатываемой системе гибкость и вертикальную расширяемость.

Для обеспечения передачи используется Kafka producer API~\cite{kafka_python_producer_api}.
Это требует определённой конфигурации.
В частности, необходимы следующие параметры, которые предоставляются в файлах конфигурации приложения:

\begin{itemize}
    \item адреса Kafka серверов;
    \item идентификатор клиента;
    \item сериализатор ключа;
    \item сериализатор значения;
    \item количество необходимых подтверждений;
    \item тип сжатия;
    \item количество попыток;
    \item размер пакета;
    \item максимальный рамер запроса;
    \item время ожидания запроса;
    \item протокол безопасности.
\end{itemize}


Ещё одним не маловажным фактором выбором Kafka является её отказоустойчивость.
Все эти сообщения будут храниться на кластере.
Тем самым, все отправленные данные не потеряются при внезапном отключении машины в кластере.

Из-за того, что в качестве промежуточного компонента используется брокер сообщений можно использовать сколько угодно блоков загрузки данных.
Таким образом достигается гибкость системы.
Для добавления нового источника данных к системе необходимо обеспечить его подключение к брокеру сообщений и использовать установленный формат сообщений.

\subsection{Блок приёма сообщений}

Блок приёма сообщений отвечает за своевременное принятие сообщений из платформы kafka.
Как только данные были получены, они сразу же начинают обработку.
Такое поведение называется потоковой обработкой (англ. stream processing).

На самом деле обрабатываеются данные, полученные за установленный период времени.
Данный промежуток времени называется окном (англ. window).
Данные, полученные за такое окно называется пакетом (англ. micro batch).
При обработке в Apache Spark каждый такой пакет будет представлять из себя отдельный RDD, над которым и будут в дальнейшем производиться все операции.

Данному блоку необходимо обеспечить получение данных из конкретных топиков для дальнейшей обработки.
Таким образом, есть возможность установить, какие именно данные начнут обрабатываться.
Как было отмечено выше, все полученные индексы используются в дальнейшей обработке, так что этот блок должен принимать данные по каждому индексу.

Источником данных служит уже рассмотренная выше платформа kafka.
С помощью установки смещения, есть возможность установить, с какого момента данные будут поступать в систему.
Тем самым можно использовать только самые актуальные данные, либо использовать предыдущие данные в качестве датасета.

Так как все приёмники объединяются в группы (англ. consumer group), то есть возможность создания блока, который будет параллельно обрабатывать те же самые данные, с точно таким же смещением.
Как раз с помощью данной особенности, данные и обрабатываются параллельно при использовании Apache Spark.
Так как код отправляется на активные машины в кластере, то и каждая машина будет параллельно получать данные из kafka платформы, а так как все они входят в одну и ту же принимающую группу, то и данные они будут получать идентичные.
Такой подход обеспечивает вертикальную масштабируемость системы.
Полученные сообщения отправляются в блок анализа данных и в блок сохранения данных.

\subsection{Блок анализа данных}

Блок анализа данных предназначен для обработки полученных данных.
Данный блок одержит математическую модель, представляющую из себя регрессионную нейронную сеть.
На основе полученных данных производится её обучение.
Так как данные подаются в рассматриваемый блок постоянно в режиме реального времени, то и внутренняя нейронная сеть обучается так же в режиме реального времени.

Подобный поход позволяет постоянно обновлять математическую модель, чтобы она была актуальной.
Однако в таком подходе есть и недостаток.
Речь идёт о проблеме переобучения.
Данная проблема заключается в ухудшении аппроксимирующей способности нейронной сети при слишком сильном обучении.
Для решения данной проблемы используются ограничения в виде максимального количества результатов, на которые будет опираться математическая модель.
Это позволит нейронной сети <<забывать>> старые данные и использовать только актуальные значения.

В качестве нейронной сети выступает метод наименьших квадратов.
Данный метод применяется для линейного регрессионного анализа.
Так как в разрабатываемой системе используются такие поля, как индекс загрязнения и год измерения, то применив регрессионный анализ можно получить зависимость индекса загрязнения от времени.
Таким образом появляется возможность вычислить тенденцию изменения индекса загрязнения на несколько лет вперёд.


Весь этот блок тесно сотрудничает с блоком визуализации данных, так как он используется в интерактивном документе Apache Zeppelin.
Результаты обработки поступают на блок визуализации данных.

\subsection{Блок сохранения данных}

Блок сохранения данных предназначен для сохранения полученных данных на диске.
Так как в качестве обработчика используется целый кластер, то и сохранение возможно осуществить как в локальной файловой системе, так и в распределённой файловой системе платформы Hadoop (англ. Hadoop Distributed File System (HDFS)).
Сохранение данных нужно для восстановления предыдущих данных после перезапуска системы.
В течении жизненного цикла приложения в данном блоке нет необходимости, так как все данные успешно хранятся в платформе Kafka.
Однако при полной перезагрузке системы, придётся заново получать данные из внешнего веб-сервиса OpenWeatherMap. 
Данный блок предназначен как раз для того, чтобы этого избежать такой проблемы.

В локальном хранилище располагаются файлы в формате JSON.
Для определения критериев, по которым был загружен конкретный файл используется преобразование исходных параметров в путь файла.
Таким образом, данные для конкретных параметров (используемого индекса, координаты и года) будут располагаться по строго заданному пути.
Такой подход используется для быстрого доступа к файлам, так как если данные и есть, то их можно получить только из определённого файла, и нет необходимости в прочитывании всех файлов для поиска.

При использовании экосистемы Hadoop появляется возможность сохранения данных в HDFS.
В отличие от локальной файловой системы, данная система является распределённой, что обеспечивает её отказоустойчивость.

Основные свойства HDFS:
\begin{itemize}
    \item Предназначена для хранения большого количества больших файлов (порядка десятков гигабайт);
    \item Оптимизирована для поддержки потокового доступа к данным (англ. high-streaming read);
    \item Ориентирована использование кластера большого размера;
    \item Отказоустойчивость.
\end{itemize}

Все накопленные данные сохраняются в локальном хранилище, что позволяет сразу загрузить уже полученные данные.
А из платформы Kafka получать только новые данные, которые ещё не были загружены.
Таким образом достигается оптимизация приложения и возможность восстановления процесса обработки при перезапуске системы.


\subsection{Блок визуализации данных}

Блок визуализации данных предназначен для интерактивного представления обработанных результатов.
Для подобного представления используется такая система, как Apache Zeppelin.
Как уже отмечалось, Apache Zeppelin использует интерактивные документы, которые используют концепцию интерпретатора, что позволяет моментально визуализировать результаты вычислений.
Данная система крайне схожа с проектом Jupyter Notebook по концепции.
Она также, как и Jupyter использует интерактивные документы (англ. notebooks).

Данный блок как раз представляет из себя интерактивный документ в системе Apache Zeppelin.
Такой подход позволяет использовать совершенно разные способы предоставления данных, а так же в режиме реального времени визуализировать текущие результаты.

Данные для визуализации загружаются из файловой системы.
Далее они преобразуются к конкретному формату:

\begin{itemize}
    \item \texttt{topic} (String);
    \item \texttt{year} (Int);
    \item \texttt{latitude} (Long);
    \item \texttt{longitude} (Long);
    \item \texttt{value} (Double).
\end{itemize}

После преобразования, необходимо получить данные только для выбранной географической координаты.
Для полученных данных производится регрессионный анализ.
После всех операций должен получиться график, который иллюстрирует полученную зависимость индекса загрязнения для конкретного географического положения.
Сама зависимость выражается коэфициентами, так что подставивь интересующее значение, получится планируемое значение индекса загрянения для указаннного года.
Таки образом можно получить зависимости для каждого индекса загрязнения и тем самым иметь возможность получить планируемое значение для временной координаты.
