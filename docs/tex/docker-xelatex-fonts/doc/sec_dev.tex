\pagebreak
\section{РАЗРАБОТКА ПРОГРАММНЫХ МОДУЛЕЙ}
\label{sec:dev}

\def\websockHandshakeScheme{ГУИР.400201.079 ПД2}

В прошлом разделе были описаны функции, имеющиеся в разрабатываемом программном обеспечении. 
В данном разделе будет описана разработка ключевых алгоритмов для данного дипломного проекта.

\subsection{Алгоритм получения данных с помощью внешнего сервиса}

В качестве источника данных может быть использовано как локальное хранилище, так и внешнее.
Если данные не были обнаружены в локальном хранилище, то они должны быть получены из внешнего сервиса.

В качестве локального хранилища может выступать как распределённая файловая система, так и локальная файловая система.
Для получения данных из подобного хранилища используется соответствующий адаптер:

\begin{itemize}
    \item \texttt{DistributedFileSystem};
    \item \texttt{DefaultFileSystem}.
\end{itemize}

Оба этих адаптера реализуют интерфейс \texttt{FileSystemAdapter}, который и используется для получения данных из локального хранилища.
С помощью файла конфигурации определяется используемая файловая система, а также параметры, которые необходимы для указания директории, в которой будут расположены хранимые данные.

В хранилище данные хранятся при помощи разбиения на корзины, как это используется в Apache HIVE.
Это означает, что данные за один год будут расположены в одной директории.
Данный подход позволяет развернуть таблицу на этих данных с помощью Apache HIVE.

Перед обращением к сервису происходит проверка запрашиваемых значений в используемой файловой системе.
Для этого запрашиваемые параметры преобразуются в строку с помощью метода \texttt{to\_file\_path}.
Поиск осуществляется в директории с запрашиваемым годом и с названием файла, полученным после преобразования параметров в название.
Если такой файл был найден, то данные из файла отправляются на дальнейшую обработку.
В противном случае производится запрос к внешнему сервису.

Для получения данных из внешнего сервиса OpenWeatherMap используется HTTP протокол.
Данные передаются в формате JSON.
Для успешного подключения необходимы следующие параметры:
\begin{itemize}
    \item API key. Специальный ключ, который предоставляется сервисом OpenWeatherMap при оформлении подписки;
    \item API Url. Адрес используемого API.
\end{itemize}

Для определения критериев выборки, на текущий момент используются следующие параметры:
\begin{itemize}
    \item географическая широта;
    \item географическая долгота;
    \item диапазон времени.
\end{itemize}

При установке соединения, на стороне сервиса происходит проверка переданного ключа.
Для используемого API на текущий момент существуют ограничения на количество запросов в промежуток времени.
По этой причине сервер проверяет количество использований переданного ключа в течении установленного промежутка.
Если текущий запрос укладывается в ограничение, то сервер отправляет запрошенные данные.
В случае, если количество запросов было превышено, то соединение удерживается на стороне сервера до тех пор, пока не истечёт установленный промежуток времени.


В любом случае, данные будут получены, и переданы на дальнейший этап обработки.
Так как данные будут получены в формате JSON, то их необходимо обработать, чтобы предоставить их в том формате, в котором они могут быть обработаны.

Полученные данные попадают в один из следующих методов в зависимости от используемого API:
\begin{itemize}
    \item \texttt{parse\_co};
    \item \texttt{parse\_so};
    \item \texttt{parse\_oz};
    \item \texttt{parse\_no}.
\end{itemize}

Каждый упомянутый выше метод используется для преобразования полученных данных из соответствующего JSON формата в список значений.
Полученный список представляет из себя выборку значений индекса загрязнения, которые соответствуют установленному критерию.
В качестве используемого критерия выступает атмосферное давление в области, где было проведено измерение индекса загрязнения.
Как было указано ранее, для выборки используются значения, полученные в заданных пределах.

После преобразования и выбора необходимых значений, они сохраняются в используемой файловой системе.
Путь сохраняемого файла определяется таким же способом, как это происходила при поиске.
Директория определяется с помощью года, за который были запрошены данные, а название файла определяется аналогичным образом с помощью метода \texttt{to\_file\_path}.

Данный алгоритм представляет из себя следующие шаги:
\begin{enumerate_step}
    \item Создаём объект класса \texttt{FileSystemAdapter} в зависимости от используемой файловой системы.
     Параметры для конструктора также определяются с помощью файла конфигурации;
    \item Преобразуем параметры для данных в строку с использованием метода \texttt{to\_file\_path} и сохраняем результат в переменную \texttt{file\_name};
    \item Выбирается параметр, используемый для разбиения для разделов. 
    Данный параметр также устанавливается с помощью файла конфигурации;
    \item С помощью вызова метода \texttt{ls} класса \texttt{FileSystemAdapter} получается список существующих директорий (разделов);
    \item Если раздел с требуемым параметром не существует, то он создаётся с помощью метода \texttt{mkdir} класса \texttt{FileSystemAdapter};
    \item В выбранном разделе с помощью метода \texttt{ls} класса \texttt{FileSystemAdapter} получается список хранимых файлов;
    \item В полученном списке происходит поиск файла с именем \texttt{file\_name};
    \item В случае, если искомый файл не был найден - происходит переход к шагу \ref{i:gbt:request};
    \item Значение вычитывается из файла с помощью метода \texttt{read\_file} класса \texttt{FileSystemAdapter};
    \item Результат в формате JSON сохраняется в переменную \texttt{value};
    \item Происходит переход к шагу \ref{i:gbt:sendMessage};
    \item \label{i:gbt:request} Создаётся объект класса \texttt{PollutionDumper} соответствующий используемому API. 
    Возможные варианты: \texttt{CODumper}, \texttt{NODumper}, \texttt{SODumper}, \texttt{OZDumper}.
    Параметры для создания этого объекта предоставляются с помощью файла конфигурации;
    \item У созданного объекта вызывается метод \texttt{dump} с текущими параметрами: географическая широта, географическая долгота, год;
    \item В вызываемом методе параметры преобразуются в адрес для GET запроса к внешнему сервису с помощью метода \texttt{to\_address};
    \item Осуществляется вызов HTTP запроса по полученному адресу;
    \item Происходит ожидание ответа;
    \item Проверяется статус ответа;
    \item В случае, если код статуса равен \texttt{200}, что соответствует корректному ответу, происходит переход к шагу \ref{i:gbt:successResponse};
    \item Выбрасывается исключение, которое обрабатывается и выводит сообщение об ошибке в лог;
    \item Происходит переход к шагу \ref{i:gbt:end};
    \item \label{i:gbt:successResponse} Ответ в формате JSON отправляется в соответствующий обработчик. 
    Возможные обработчики: функция \texttt{parse\_co}, функция \texttt{parse\_so}, функция \texttt{parse\_no}, функция \texttt{parse\_oz};
    \item В обработчике происходит преобразование данных в соответствующем формате JSON в список значений;
    \item Результат обработки сохраняется в переменную \texttt{value};
    \item Происходит запись переменной \texttt{value} в файл с именем \texttt{file\_name} с помощью метода \texttt{write\_file}.
    \item \label{i:gbt:sendMessage} Используемые параметры также преобразуются в формат JSON и сохраняется в переменную \texttt{key};
    \item Создаётся объект класса \texttt{KafkaSender}, с параметрами, указанными в файле конфигурации;
    \item Вызывается метод \texttt{send\_message} созданного объекта класса \texttt{KafkaSender}, в который передаются значения: \texttt{key}, \texttt{value}, топик и параметры. 
    Используемый топик также определяется с помощью файла конфигурации и зависит от текущего API;
    \item Отправитель ожидает подтверждения отправки сообщения в течении установленного времени;
    \item При успешной отправке, вызывается метод \texttt{callback}, который отправляет в лог сообщение об успешной отправке сообщения, и выводит метаинформацию отправленного сообщения.
    \item Если отправка сообщения не произошла - выбрасывается исключение;
    \item \label{i:gbt:end} Происходит переход к следующей итерации.
\end{enumerate_step}

Данный алгоритм также представлен на диаграмме последовательности ГУИР.400201.079 РР3.
Также данный алгоритм  более подробно представлен на блок схеме ГУИР.400201.079 ПД1.


\subsection{Алгоритм отправки данных}

Подготовленные данные отправляются в Kafka.
Для каждого типа индекса загрязнения выделен отдельный топик.
Каждое сообщение из себя представляет комбинацию ключа и значения.
Для ключа и значения устанавливается функция, которая будет преобразовывать данные при отправке в массив данных.
Данное преобразование необходимо для поддержки пользовательского формата данных и тем самым предоставляет возможность отправлять и хранить любой объект.

В качестве ключа используются параметры, которые были использованы при получении данных:
\begin{itemize}
    \item год, в котором было проведено измерение;
    \item географическая широта области, в которой было проведено измерение;
    \item географическая долгота области, в которой было проведено измерение.
\end{itemize}

Все эти параметры преобразуются в строку в формате JSON.
Полученная строка выступает в качестве ключа в отправляемом сообщении.
В качестве значения выступает список значений и соответствующего атмосферного давления, представляющий обработанные данные.
Значение также передаётся в формате JSON.

Каждый тип измерений отправляется в свой топик, который определяется с помощью файла конфигурации.
Также с помощью файла конфигураций устанавливаются правила поведения объекта, который отвечает за отправку сообщений.
Данные параметры уже были рассмотрены в предыдущем разделе.
Они влияют на алгоритм установки соединения, возможность восстановления потерянного соединения, безопасность передачи данных и размер пакета.

Также при отправке устанавливается функция обратного вызова (англ. \texttt{callback}), что позволяет получить метаинформацию отправленного сообщения и тем самым подтвердить успешную отправку сообщения.
После отправки сообщения, отправитель ждёт ответа от брокера в качестве подтверждения доставки.
В качестве подтверждения, брокер высылает метаинформацию полученного сообщения.
Как только ответ был получен, вызывается установленный метод \texttt{callback}.

\subsection{Алгоритм получения данных}

Получение данных осуществляется в режиме реального времени с помощью технологии Spark streaming.
Для осуществления подобного функционала используется пакетная обработка данных.
С помощью установленных в конфигурационном файле параметров создаётся виртуальный поток данных.
Такой поток данных является виртуальным, так как на самом деле потока как такового не существует, но с помощью него описываются действия, которые будут производиться с каждым полученным пакетом данных.
Подобный подход используется при описании вычислений на распределённом датасете, так как он существует только во время исполнения программы.

Виртуальный поток представляет из себя поток данных, которые будут получены из kafka топиков, которые приводятся в файле конфигурации.
Так как данные приходят в уже определённом формате, то их для начала необходимо разобрать на поля.
Из ключа сообщения можно получить переданные поля в формате JSON:
\begin{itemize}
    \item год, в котором было проведено измерение;
    \item географическая широта области, в которой было проведено измерение;
    \item географическая долгота области, в которой было проведено измерение.
\end{itemize}

Благодаря такой обработке, получаем распределённый датасет (RDD) уже с несколькими полями.
А так как значения сообщения из себя представляет список значений индекса и соответствующего атмосферного давления, то для каждой такой записи предыдущие параметры будут одинаковые.

В результате всех преобразований получается распределённый датасет (RDD), состоящий из нескольких полей:
\begin{itemize}
    \item топик из которого было получено сообщение;
    \item год, в котором было проведено измерение;
    \item географическая широта области, в которой было проведено измерение;
    \item географическая долгота области, в которой было проведено измерение;
    \item значение измеряемого индекса загрязнения.
\end{itemize}

Полученный датасет сохраняется в одном из следующих форматов:
\begin{itemize}
    \item \texttt{orc}. Данный формат эффективен для хранения больших объёмов данных, так как использует сжатие. Также данный формат структурированный, что позволяет использовать пропуск полей (англ. file prunning). Это значит, что при чтении такого файла для определённого запроса, Apache Spark может пропускать не используемые в запросе поля, и не тратить время на их распаковку;
    \item \texttt{csv}. Данный формат эффективен для хранения данных в строгой структуре;
    \item \texttt{json}. Данный формат эффективен для хранения сложной структуры данных;
    \item \texttt{parquet}. Данный формат эффективен для файлов, которые часто подвергаются чтению, и редко подвергаются записи;
    \item \texttt{avro}. Данный формат эффективен для сложных данных с изменяемой структурой.
\end{itemize}

Для полученных данных лучше всего подходят форматы \texttt{parquet} и \texttt{orc} по причине неизменяемости данных.
Однако формат может быть установлен на любой другой по желанию, так как данный параметр устанавливается в конфигурационном файле.

Также Apache Spark поддерживает разделение на разделы, что уже было отмечено выше.
В текущей ситуации под разделение лучше всего подходит поле с годом осуществления измерения.
Такое решение исходит из того, большая часть данных имеет одинаковый год, и при анализе часто будут браться данные по конкретному году.
Это позволит оптимизировать операции выбора и фильтрации данных, что повысит производительность системы.

На этих данных развёртывается таблица с помощью Apache Spark.
Это позволяет использовать преобразованные данные для дальнейшего анализа.
Как только будет получен новый пакет, после преобразования он также добавится уже в существующую таблицу, тем самым обеспечив её обновление в режиме реального времени.

Сами же пакеты данных образуются с помощью использования так называемого окна (англ. window).
Окно представляет из себя промежуток времени.
Данные, которые были получены за этот промежуток времени и являются пакетом.
Размер используемого окна также определяется с помощью конфигурационного файла.

В результате получается следующий алгоритм:
\begin{enumerate_step}
    \item Создаётся объект словаря \texttt{params};
    \item В словарь \texttt{params} добавляются параметры получателя, которые определяются с помощью файла конфигурации;
    \item Происходит инициализация spark-контекста;
    \item Устанавливается мастер, который определяется файлом конфигурации. 
    Используемый мастер может быть как локальный, так и удалённый;
    \item Устанавливаем размер окна для дальнейшей потоковой обработки;
    \item Происходит инициализация spark-streaming контекста;
    \item С помощью словаря \texttt{params}, созданного spark-контекста, а также топиков, которые определяются файлом конфигурации, создаётся объект виртуального потока - объект \texttt{stream} класса \texttt{DStream[String, String]};
    \item Для виртуального потока \texttt{stream} с помощью метода \texttt{mapPartition} определяется лямбда-функция, которая будет исполняться для каждого полученного раздела;
    \item В этой функции с помощью метода \texttt{map} определяется лямбда-функция, которая будет применяться к каждой записи в разделе;
    \item \label{i:gbt:map} В каждой записи получаем ключ и значение и записываем в переменные \texttt{key} и \texttt{value} соответственно;
    \item С помощью метода \texttt{parse\_key} получаем следующие поля: географическая широта (\texttt{latitude}), географическая долгота (\texttt{longitude}), год (\texttt{year});
    \item С помощью метода \texttt{parse\_value} получаем список со следующими полями: атмосферное давление (\texttt{pressure}), значение измерения (\texttt{value});
    \item Для каждого значения в обработанном \texttt{value} копируем соответствующие параметры (поля из обработанного \texttt{key});
    \item В результате трансформации получается распределённый датасет (RDD) со следующими полями: \texttt{latitude}, \texttt{longitude}, \texttt{year}, \texttt{value};
    \item Объединяется с другими полученными в текущем окне датасетами;
    \item Сохраняет текущее смещение (\texttt{offset}) получателя с помощью метода \texttt{checkpoint};
    \item Ожидаем следующий пакет, пока окно не закончилось. 
    При его появлении переходим к шагу \ref{i:gbt:map};
    \item Если окно закончилось, то весь объединённый датасет записывается в переменную \texttt{resultRdd};
    \item Полученный датасет в переменной \texttt{resultRdd} записывается в формат, установленный в файле конфигурации с помощью метода \texttt{write};
    \item Полученный датасет добавляется в базу с помощью метода \texttt{withTempView};
    \item Происходит переход к следующему временному окну;
    \item Переход к шагу \ref{i:gbt:map}.
\end{enumerate_step}

Такой алгоритм работает бесконечно, пока не будет остановлен spark-контекст, либо при возникновении ошибки.
Похожий принцип используется при разработке веб-серверов.

Данный алгоритм также представлен на диаграмме последовательности ГУИР.400201.079 РР2.


\subsection{Алгоритм анализа данных}

Сам анализ данных осуществляется в интерактивном документе Zeppelin.
Это вносит возможность взаимодействия сразу с несколькими интерпретаторами.
В качестве анализа используется линейная регрессия полученных индексов загрязнения от года.
Результатом анализа служат коэфициенты, отображающие найденную линейную зависимость. 

Для анализа используется следующий алгоритм:
\begin{enumerate_step}
    \item Данные выгружаются из временной таблицы;
    \item Выбирается исследумая географическая координата при помощи формы ввода в интерактивном документе;
    \item Загруженные данные фильтруются, оставляя только данные для выбранной географической координаты;
    \item Полученные данные агрегируются и собираются в один объект из всех используемых рабочих узлов;
    \item Формируется список \texttt{year} из года из полученных данных;
    \item Формируется список \texttt{value} из значения из полученных данных;
    \item Список \texttt{year} преобразуется в матрицу \texttt{Y};
    \item Список \texttt{value} преобразуется в матрицу \texttt{A} с дополнительным первым единичным столбцом;
    \item Матрица \texttt{A} транспонируется и записывается в переменную \texttt{At};
    \item Находится произведение матриц \texttt{At} и \texttt{A}. Результат записывается в переменную \texttt{AAt};
    \item Находится обратная матрица для матрицы \texttt{AAt}. Результат записывается в переменную \texttt{AAt1};
    \item Находится произведение матриц \texttt{AAt1} и \texttt{At}. Результат записывается в переменную \texttt{AAt1At};
    \item Находится произведение матриц \texttt{AAt1At} и \texttt{Y}. Результат записывается в переменную \texttt{theta};
    \item Находится произведение матриц \texttt{theta} и \texttt{X}. Результат записывается в переменную \texttt{Y_pred};
    \item Полученная матрица \texttt{Y_pred} преобразуется в список;
    \item По полученным данным в матрице \texttt{Y_pred} строится график.
\end{enumerate_step}
